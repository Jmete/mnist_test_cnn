# -*- coding: utf-8 -*-
"""mnist_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wJHtLgwIFqcXi_j8N3JJz3l9uS9jVP0K
"""

import tensorflow as tf
import numpy as np
from keras import layers
from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D
from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D
from keras.models import Model

data = tf.keras.datasets.mnist

(x_train,y_train),(x_test,y_test) = data.load_data()

x_train = tf.keras.utils.normalize(x_train,axis=1)
x_test = tf.keras.utils.normalize(x_test,axis=1)

x_train = x_train.reshape(x_train.shape[0],28,28,1)
x_test = x_test.reshape(x_test.shape[0],28,28,1)
print(x_train.shape)
print(y_train.shape)

print(x_train[0].shape)
print(y_train[0])

import matplotlib.pyplot as plt

plt.imshow(x_train[0].reshape(28,28), cmap = plt.cm.binary)
plt.show()

def digit_model(input_shape):
  X_input = Input(input_shape)
  
  X = ZeroPadding2D((3,3))(X_input)
  
  X = Conv2D(12,(3,3), strides = (1,1), name = 'conv0')(X)
  X = BatchNormalization(axis = 3, name = 'bn0')(X)
  X = Activation('relu')(X)
  
  X = MaxPooling2D((2,2), name='max_pool0')(X)
  
  X = Dropout(0.4)(X)
  
  X = Conv2D(24,(2,2), strides = (1,1), name = 'conv1')(X)
  X = BatchNormalization(axis = 3, name = 'bn1')(X)
  X = Activation('relu')(X)
  
  X = MaxPooling2D((2,2), name='max_pool1')(X)
  
  X = Flatten()(X)
  
  X = Dense(10, activation='softmax', name='fc')(X)
  
  model = Model(inputs=X_input, outputs = X, name='DigitModel')
  
  return model

digitModel = digit_model((28,28,1))

digitModel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

digitModel.fit(x = x_train, y=y_train,epochs = 3,batch_size=32)

v_loss, v_acc = digitModel.evaluate(x_test,y_test)
print(v_loss,v_acc)

preds = digitModel.predict([x_test])

print(np.argmax(preds[20]))

plt.imshow(x_test[20].reshape(28,28))
plt.show()

