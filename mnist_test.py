# -*- coding: utf-8 -*-
"""mnist_test.ipynb

Automatically generated by Colaboratory.

By James Mete
jamesmete.com
"""
# Not all of these are used. However, they can be switched out to test different results. 
# Importing directly makes writing the code easier later.

import tensorflow as tf
import numpy as np
from keras import layers
from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D
from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D
from keras.models import Model
import matplotlib.pyplot as plt

#Importing mnist data
data = tf.keras.datasets.mnist

(x_train,y_train),(x_test,y_test) = data.load_data()

x_train = tf.keras.utils.normalize(x_train,axis=1)
x_test = tf.keras.utils.normalize(x_test,axis=1)

#Reshaping to make sure the filter dimension is there (the channel).
x_train = x_train.reshape(x_train.shape[0],28,28,1)
x_test = x_test.reshape(x_test.shape[0],28,28,1)

#Testing
print(x_train.shape)
print(y_train.shape)

print(x_train[0].shape)
print(y_train[0])

#Plot an image for testing.
plt.imshow(x_train[0].reshape(28,28), cmap = plt.cm.binary)
plt.show()

#Creating the model

def digit_model(input_shape):
  X_input = Input(input_shape)
  

  X = ZeroPadding2D((3,3))(X_input)

  X = Conv2D(12,(3,3), strides = (1,1), name = 'conv0')(X)
  X = BatchNormalization(axis = 3, name = 'bn0')(X)
  X = Activation('relu')(X)
  
  X = MaxPooling2D((2,2), name='max_pool0')(X)
  
  X = Dropout(0.4)(X)
  
  X = Conv2D(24,(2,2), strides = (1,1), name = 'conv1')(X)
  X = BatchNormalization(axis = 3, name = 'bn1')(X)
  X = Activation('relu')(X)
  
  X = MaxPooling2D((2,2), name='max_pool1')(X)
  
  X = Flatten()(X)
  
  X = Dense(10, activation='softmax', name='fc')(X)
  
  model = Model(inputs=X_input, outputs = X, name='DigitModel')
  
  return model

#Create model with proper input shape according to our image data.
digitModel = digit_model((28,28,1))

#Compile the image. Sparse categorical because our y labels are integers and NOT represented in one-hot or categorical format.
digitModel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

#Train the model.
digitModel.fit(x = x_train, y=y_train,epochs = 3,batch_size=32)

#Evaluate the model on the test set.
v_loss, v_acc = digitModel.evaluate(x_test,y_test)
print(v_loss,v_acc)

#Create predictions
preds = digitModel.predict([x_test])

#Testing the results by sampling the predictions and plotting the result.
print(np.argmax(preds[20]))

plt.imshow(x_test[20].reshape(28,28))
plt.show()

